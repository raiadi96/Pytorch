{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentenceClassifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHWvlKJJrwXM9fADRbHfnz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raiadi96/Pytorch/blob/master/SentenceClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbGPX0G6AxQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSaH1dPLA7VR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "6879ad23-158d-43d3-ff75-bea07fe182ed"
      },
      "source": [
        "data_yelp = pd.read_table('/content/yelp_labelled.txt')\n",
        "data_imdb = pd.read_table('/content/imdb_labelled.txt')\n",
        "data_amazon = pd.read_table('/content/amazon_cells_labelled.txt')\n",
        "\n",
        "#concatenate the tables in 1 list \n",
        "\n",
        "frames = [data_yelp, data_imdb, data_amazon]\n",
        "\n",
        "for colname in frames:\n",
        "  print(colname.columns)\n",
        "\n",
        "# as we can see there is no colum header so first we will a column header for all the data frames\n",
        "\n",
        "for colname in frames:\n",
        "  colname.columns = ['Message',  'Target']\n",
        "  print(colname.columns)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Wow... Loved this place.', '1'], dtype='object')\n",
            "Index(['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  ', '0'], dtype='object')\n",
            "Index(['So there is no way for me to plug it in here in the US unless I go by a converter.', '0'], dtype='object')\n",
            "Index(['Message', 'Target'], dtype='object')\n",
            "Index(['Message', 'Target'], dtype='object')\n",
            "Index(['Message', 'Target'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvC_hQzHC1NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = ['yelp', 'imdb', 'amazon']\n",
        "\n",
        "dataset = pd.concat(frames, keys= keys)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLn91qWQDmz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b3dd32f0-879f-433c-8889-016afb5d5eda"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Message</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">yelp</th>\n",
              "      <th>0</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Now I am getting angry and I want my damn pho.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Message  Target\n",
              "yelp 0                                 Crust is not good.       0\n",
              "     1          Not tasty and the texture was just nasty.       0\n",
              "     2  Stopped by during the late May bank holiday of...       1\n",
              "     3  The selection on the menu was great and so wer...       1\n",
              "     4     Now I am getting angry and I want my damn pho.       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xan8dcALDoif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b4ad04c2-03f7-429f-a819-f7788eb90a09"
      },
      "source": [
        "#check if any of the columns has null values\n",
        "\n",
        "dataset.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Message    0\n",
              "Target     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgqOquPODyj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will now remove the stopwords and lemmatize the text\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "nlp = spacy.load('en')\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlkKUlWREEcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ed67a86f-1f11-4c13-80b6-c964ddc328bf"
      },
      "source": [
        "stop_words = list(STOP_WORDS)\n",
        "stop_words[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['since',\n",
              " 'whose',\n",
              " 'you',\n",
              " \"'d\",\n",
              " 'nâ€˜t',\n",
              " 'amount',\n",
              " 'thereupon',\n",
              " 'this',\n",
              " 'almost',\n",
              " 'once']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSn6d3AbEH6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a spacy parser\n",
        "from spacy.lang.en import English\n",
        "parser = English()\n",
        "import string\n",
        "\n",
        "#create a custom tokenizer and stop word removal method\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "  myToken = parser(sentence)\n",
        "  myToken = [word.lemma_.lower().strip() if word.lemma_ != '--PRON--' else wprd.lower_ for word in myToken]\n",
        "  myToken =  [word  for word in myToken if word not in stop_words and word not in string.punctuation]\n",
        "  return myToken"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaKqz5toH0HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import sklearn packages\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IshYEUuIUyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformer(TransformerMixin):\n",
        "  def transform(self, X, **transform_params):\n",
        "    return [clean_text(text) for text in X]\n",
        "  \n",
        "  def fit(self, X, y = None, **fit_params):\n",
        "    return self\n",
        "  \n",
        "  def get_params(self, deep = True):\n",
        "    return {}\n",
        "\n",
        "def clean_text(sent):\n",
        "  return sent.strip().lower()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mMOx7gJAnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer= spacy_tokenizer, ngram_range= (1,1))\n",
        "classifier = LinearSVC()\n",
        "\n",
        "#tfidf vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(tokenizer= spacy_tokenizer)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXImVtkHJXYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y  = dataset['Message'],dataset['Target']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KayFIFUxKBrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_text, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXyKUIutKoTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipe = Pipeline([\n",
        "                 (\"cleaner\", CustomTransformer()),\n",
        "                 (\"vectorizer\", vectorizer),\n",
        "                 (\"classifier\", classifier)\n",
        "])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoScFp-fLFVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "01049e66-3605-41c0-93e4-3a129126e0fb"
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner',\n",
              "                 <__main__.CustomTransformer object at 0x7f9e9026ba58>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenizer at 0x7f9e9d3dfe18>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
              "                           fit_intercept=True, intercept_scaling=1,\n",
              "                           loss='squared_hinge', max_iter=1000,\n",
              "                           multi_class='ovr', penalty='l2', random_state=None,\n",
              "                           tol=0.0001, verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIrecrBnLM6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vectorizer_predictions = pipe.predict(X_text)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lmDNJDOLmPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "11fd4359-72e6-4a27-e730-b4f0b8e9453b"
      },
      "source": [
        "count_vectorizer_predictions"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTvq6MuLLp7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}